{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc83547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import happybase\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daaa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from functools import reduce\n",
    "from pyspark.sql.types import DateType, StringType,ArrayType\n",
    "from pyspark.sql.functions import rank,col, when, date_format, explode, split,regexp_replace, udf, datediff, avg, count,countDistinct,first, expr,lit\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VM_adress = 'localhost'\n",
    "connection = happybase.Connection(VM_adress, timeout=999999)\n",
    "dynamic_table = connection.table('daily_data')\n",
    "static_table = connection.table('spotify_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja sesji Spark\n",
    "spark = SparkSession.builder.appName(\"SpotifyAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_df(tab, spark):\n",
    "    data_list = []\n",
    "    \n",
    "    for key, data in tab.scan(None):\n",
    "        key_decoded = key.decode('utf-8')\n",
    "        row_dict = {'id': key_decoded}\n",
    "    \n",
    "        for column, value in data.items():\n",
    "            column_decoded = column.decode('utf-8')\n",
    "            value_decoded = value.decode('utf-8')\n",
    "            row_dict[column_decoded] = value_decoded\n",
    "    \n",
    "        data_list.append(row_dict)\n",
    "        \n",
    "    spark_df = spark.createDataFrame(data_list)\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = create_spark_df(dynamic_table, spark)\n",
    "spotify_songs = create_spark_df(static_table, spark)\n",
    "\n",
    "dynamic_df = reduce(lambda df, col_name: df.withColumnRenamed(col_name, col_name.replace(\"data:\", \"\")), daily_data.columns, daily_data)\n",
    "static_df = reduce(lambda df, col_name: df.withColumnRenamed(col_name, col_name.replace(\"data:\", \"\")), spotify_songs.columns, spotify_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95142c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcje do przetworzenia ramek i agregacji\n",
    "\n",
    "def remove_conflicting_columns(df, drop_columns):\n",
    "    return df.drop(*drop_columns)\n",
    "\n",
    "def mark_missing_tracks(df,faulty_df):\n",
    "    df_ids = df.select(\"track_id\")\n",
    "    faulty_df_ids = faulty_df.select(\"track_id\")\n",
    "    missing_tracks = df_ids.subtract(faulty_df_ids)\n",
    "    missing_tracks_list = missing_tracks.rdd.map(lambda x: x[0]).collect()\n",
    "    return df.withColumn(\"missing\", col(\"track_id\").isin(missing_tracks_list))\n",
    "\n",
    "def merge_dataframes(dynamic_df, static_df):\n",
    "    merged_df = dynamic_df.join(static_df, \"track_id\", \"left_outer\")\n",
    "    return merged_df\n",
    "\n",
    "def assure_date_type(df, date_columns):\n",
    "    for column in date_columns:\n",
    "        df = df.withColumn(column, col(column).cast(DateType()))\n",
    "    return df\n",
    "\n",
    "def assign_unique_track_id(df):\n",
    "    windowSpec = Window().partitionBy(\"track_id\", \"artist_id\", \"track_album_name\").orderBy(\"track_album_release_date\")\n",
    "\n",
    "    updated_df = df.withColumn(\"track_id\", first(\"track_id\").over(windowSpec)) \\\n",
    "        .withColumn(\"track_album_release_date\", first(\"track_album_release_date\").over(windowSpec)) \\\n",
    "        .withColumn(\"missing\", first(\"missing\").over(windowSpec))\n",
    "    return updated_df\n",
    "\n",
    "def add_season_column(df):\n",
    "    return df.withColumn(\n",
    "        \"season\",\n",
    "        when(\n",
    "            (date_format(col(\"date_added\"), \"MM-dd\").between(\"12-22\", \"12-31\")) |\n",
    "            (date_format(col(\"date_added\"), \"MM-dd\").between(\"01-01\", \"03-20\")),\n",
    "            \"Winter\"\n",
    "        ).when(\n",
    "            date_format(col(\"date_added\"), \"MM-dd\").between(\"03-21\", \"06-21\"),\n",
    "            \"Spring\"\n",
    "        ).when(\n",
    "            date_format(col(\"date_added\"), \"MM-dd\").between(\"06-22\", \"09-22\"),\n",
    "            \"Summer\"\n",
    "        ).when(\n",
    "            date_format(col(\"date_added\"), \"MM-dd\").between(\"09-23\", \"12-21\"),\n",
    "            \"Autumn\"\n",
    "        ).otherwise(\"None\")\n",
    "    )\n",
    "\n",
    "def add_seasonal_event_column(df):\n",
    "    return df.withColumn(\"seasonal_event\", \n",
    "        when(\n",
    "            date_format(col(\"date_added\"), \"MM-dd\").between(\"12-02\", \"12-28\"),\n",
    "            \"Christmas\"\n",
    "        ).otherwise(\n",
    "            when(\n",
    "                date_format(col(\"date_added\"), \"MM-dd\").between(\"01-01\", \"01-02\"),\n",
    "                \"New Year\"\n",
    "            ).otherwise(\n",
    "                when(\n",
    "                    (col(\"date_added\").between(\"2024-01-07\", \"2024-03-06\")),\n",
    "                    \"Carnival\"\n",
    "                ).otherwise(\"Normal\")\n",
    "            )))\n",
    "\n",
    "def assign_main_genre(genre):\n",
    "    list =[]\n",
    "    \n",
    "    if \"pop\" in genre:\n",
    "        list.append( \"pop\")\n",
    "    if \"rock\" in genre:\n",
    "        list.append(  \"rock\")\n",
    "    if \"hip hop\" in genre:\n",
    "        list.append(  \"hip hop\")\n",
    "    if \"jazz\" in genre:\n",
    "        list.append(\"jazz\")\n",
    "    if any(keyword in genre for keyword in [\"electronic\", \"edm\", \"trap\"]):\n",
    "        list.append(\"electronic\")\n",
    "    if any(keyword in genre for keyword in [\"'rap\",\" rap\"]):\n",
    "        list.append(\"rap\")\n",
    "    if \"country\" in genre:\n",
    "        list.append(\"country\")\n",
    "    if any(keyword in genre for keyword in [\"r&b\", \"soul\"]):\n",
    "        list.append(  \"r&b/soul\")\n",
    "    if any(keyword in genre for keyword in [\"reggaeton\", \"latino\"]):\n",
    "        list.append(  \"reggaeton/latino\")\n",
    "    if any(keyword in genre for keyword in [\"classical\", \"orchestral\"]):\n",
    "        list.append(  \"classical/orchestral\")\n",
    "    if \"unknown\" in genre:\n",
    "        list.append(  \"unknown\")\n",
    "    if any(keyword in genre for keyword in [\"alternative\", \"alt\", \"indie\"]):\n",
    "        list.append(  \"alternative/indie\")\n",
    "    if len(list)>0:\n",
    "        return list\n",
    "    else:\n",
    "        return [\"other\"]\n",
    "\n",
    "def transform_artist_genres(df):\n",
    "    # Rozpakuj listy w poszczególne wiersze\n",
    "    df = df.withColumn(\"artist_subgenres\", regexp_replace(col(\"artist_genres\"), \"[\\[\\]']\", \"\"))\\\n",
    "            .withColumn(\"artist_main_genres\", assign_main_genre_udf(\"artist_subgenres\"))\n",
    "    \n",
    "    df = remove_conflicting_columns(df, [\"artist_genres\"])\n",
    "    df = df.dropDuplicates(subset=[\"track_id\", \"artist_main_genres\",\"date_added\"])\n",
    "    return df\n",
    "\n",
    "def add_track_age(df):    \n",
    "    df = df.withColumn(\"track_age\", datediff(col(\"date_added\"), col(\"track_album_release_date\"))) \\\n",
    "            .withColumn(\"released_within_a_month\", when(col(\"track_age\") <= 31, 1).otherwise(0)) \\\n",
    "            .withColumn(\"released_within_a_year\", when(col(\"track_age\") <= 365, 1).otherwise(0)) \\\n",
    "            .withColumn(\"duration_min\", expr(\"duration_ms / 60000\")) \\\n",
    "            .withColumn(\"day_of_week\", date_format(col(\"date_added\"), \"EEEE\"))\\\n",
    "            .withColumn(\"month\", date_format(col(\"date_added\"), \"MM\"))\n",
    "\n",
    "    return df\n",
    "\n",
    "def compare_released_within_a_month(df,column): \n",
    "    num_tracks = 50\n",
    "    max_rank_sum = sum(1/i for i in range(1, 50+1))\n",
    "    const = num_tracks*max_rank_sum\n",
    "\n",
    "    # Definiowanie kryteriów popularności gatunku\n",
    "    popularity_criteria = expr(\"(SUM(1/rank) * COUNT(*)) / (POW(total_days, 2) * {})\".format(const))\n",
    "    \n",
    "     # Porównanie rankingu utworów z ostatnio wydanej płyty z innymi utworami\n",
    "    comparison_df = df.groupBy(column,\"released_within_a_month\",\"total_days\").agg(\n",
    "         popularity_criteria.alias(\"group_popularity\"),\n",
    "        (count(\"*\") / (num_tracks * col(\"total_days\")) * 100).alias(\"average_percent_of_top_50\")).orderBy(column).select(column,\"released_within_a_month\",\"group_popularity\",\"average_percent_of_top_50\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def compare_released_within_a_year(df,column):   \n",
    "    num_tracks = 50\n",
    "    max_rank_sum = sum(1/i for i in range(1, 50+1))\n",
    "    const = num_tracks*max_rank_sum\n",
    "    \n",
    "    # Definiowanie kryteriów popularności gatunku\n",
    "    popularity_criteria = expr(\"(SUM(1/rank) * COUNT(*)) / (POW(total_days, 2) * {})\".format(const))\n",
    "\n",
    "     # Porównanie rankingu utworów z ostatnio wydanej płyty z innymi utworami\n",
    "    comparison_df = df.groupBy(column,\"released_within_a_year\",\"total_days\").agg(\n",
    "         popularity_criteria.alias(\"group_popularity\"),\n",
    "        (count(\"*\") / (num_tracks * col(\"total_days\")) * 100).alias(\"average_percent_of_top_50\")).orderBy(column).select(column,\"released_within_a_year\",\"group_popularity\",\"average_percent_of_top_50\")\n",
    "    return comparison_df\n",
    "\n",
    "def get_top_tracks(df,column):\n",
    "  \n",
    "    num_tracks = 50\n",
    "    \n",
    "    # Definiowanie kryteriów popularności gatunku\n",
    "    popularity_criteria = expr(\"(SUM(1/rank) * COUNT(*)*100) / (total_days*{})\".format(num_tracks))\n",
    "    \n",
    "    other_columns = ['track_name','artist','track_album_name']\n",
    "    comparison_df = df.groupBy(column,\"artist_main_genres\",*other_columns,\"track_id\",\"total_days\").agg(\n",
    "        count(\"track_id\").alias(\"days_on_chart\"),\n",
    "        popularity_criteria.alias(\"track_popularity\"),\n",
    "        avg(\"track_age\").alias(\"average_track_age\"),\n",
    "        )\n",
    "    \n",
    "    comparison_df = comparison_df.select(column,*other_columns,\"track_popularity\",\"artist_main_genres\",\"days_on_chart\",\"average_track_age\").orderBy(column,col(\"track_popularity\").desc())\n",
    "    # Utwórz okno partycjonujące po kolumnie 'grupa' i sortujące po kolumnie 'wartość' malejąco\n",
    "    window_spec = Window().partitionBy(column).orderBy(comparison_df[\"track_popularity\"].desc())\n",
    "    # Dodaj kolumnę rankingu dla każdej grupy\n",
    "    comparison_df = comparison_df.withColumn(\"rank\", rank().over(window_spec))\n",
    "\n",
    "    # Wybierz top 5 z każdej grupy\n",
    "    comparison_df = comparison_df.filter(\"rank <= 5\").drop(\"rank\")\n",
    "    return comparison_df\n",
    "\n",
    "def get_top_artists(df,column):\n",
    "    other_columns = ['artist']\n",
    "  \n",
    "    num_tracks = 50\n",
    "    max_rank_sum = sum(1/i for i in range(1, 50+1))\n",
    "    const = num_tracks*max_rank_sum\n",
    "    \n",
    "    # Definiowanie kryteriów popularności gatunku\n",
    "    popularity_criteria = expr(\"(SUM(1/rank) * COUNT(*)) / (POW(total_days, 2)*{})\".format(const))\n",
    "\n",
    "    # Agregacja danych dla każdego artysty\n",
    "    comparison_df = df.groupBy(column,\"artist_main_genres\",*other_columns,\"artist_id\",\"total_days\").agg(\n",
    "        countDistinct(\"track_id\").alias(\"number_of_tracks\"),\n",
    "        popularity_criteria.alias(\"artist_popularity\"),\n",
    "        avg(\"track_age\").alias(\"average_track_age\"),\n",
    "        expr(\"collect_set(track_album_name)\").alias(\"artist_albums\"),\n",
    "        avg(\"duration_min\").alias(\"average_duration_min\"),\n",
    "        avg(\"danceability\").alias(\"average_danceability\"),\n",
    "        avg(\"energy\").alias(\"average_energy\"),\n",
    "        avg(\"key\").alias(\"average_key\"),\n",
    "        avg(\"loudness\").alias(\"average_loudness\"),\n",
    "        avg(\"mode\").alias(\"average_mode\"),\n",
    "        avg(\"speechiness\").alias(\"average_speechiness\"),\n",
    "        avg(\"acousticness\").alias(\"average_acousticness\"),\n",
    "        avg(\"instrumentalness\").alias(\"average_instrumentalness\"),\n",
    "        avg(\"liveness\").alias(\"average_liveness\"),\n",
    "        avg(\"valence\").alias(\"average_valence\"),\n",
    "        avg(\"tempo\").alias(\"average_tempo\")\n",
    "        ).orderBy(column,col(\"artist_popularity\").desc())\n",
    "    comparison_df = comparison_df.select(column,*other_columns,\"artist_popularity\",\"number_of_tracks\", \"average_track_age\", \"artist_main_genres\", \"artist_albums\", \"average_duration_min\", \"average_danceability\", \"average_energy\", \"average_key\", \"average_loudness\", \"average_mode\", \"average_speechiness\", \"average_acousticness\", \"average_instrumentalness\", \"average_liveness\", \"average_valence\", \"average_tempo\")\n",
    "    # Utwórz okno partycjonujące po kolumnie 'grupa' i sortujące po kolumnie 'wartość' malejąco\n",
    "    window_spec = Window().partitionBy(column).orderBy(comparison_df[\"artist_popularity\"].desc())\n",
    "    # Dodaj kolumnę rankingu dla każdej grupy\n",
    "    comparison_df = comparison_df.withColumn(\"rank\", rank().over(window_spec))\n",
    "\n",
    "    # Wybierz top 5 z każdej grupy\n",
    "    comparison_df = comparison_df.filter(\"rank <= 5\").drop(\"rank\")\n",
    "    return comparison_df\n",
    "    \n",
    "def get_top_genres(df,column):\n",
    "    # Dodaj kolumnę \"main_genre\" do ramki danych\n",
    "    df1 = df.withColumn(\"genres\", split(df[\"artist_subgenres\"], \",\"))\\\n",
    "            .withColumn(\"genres\", explode(\"genres\"))\\\n",
    "            .withColumn(\"artist_main_genres\", assign_main_genre_udf(\"genres\"))\\\n",
    "            .withColumn(\"artist_main_genres\", explode(\"artist_main_genres\"))\n",
    "\n",
    "    df2 = df1.dropDuplicates(subset=[\"track_id\",\"track_age\",\"artist_main_genres\"])\n",
    "\n",
    "    num_tracks = 50\n",
    "    max_rank_sum = sum(1/i for i in range(1, 50+1))\n",
    "    const = num_tracks*max_rank_sum\n",
    "    \n",
    "    # Definiowanie kryteriów popularności gatunku\n",
    "    popularity_criteria = expr(\"(SUM(1/rank) * COUNT(*)) / (POW(total_days, 2)*{})\".format(const))\n",
    "    \n",
    "    # Agregacja danych dla każdego gatunku\n",
    "    comparison_df = df2.groupBy(column,\"total_days\",\"artist_main_genres\").agg(\n",
    "        popularity_criteria.alias(\"genre_popularity\"),\n",
    "        countDistinct(\"track_id\").alias(\"number_of_tracks\")\n",
    "        )\n",
    "        \n",
    "    # Agregacja subgatunków dla każdego głównego gatunku\n",
    "    subgenres_df = df1.groupBy(column,\"artist_main_genres\").agg(\n",
    "        expr(\"collect_set(genres)\").alias(\"artist_subgenres\")\n",
    "        ).dropDuplicates()\n",
    "    \n",
    "    # Połączenie dwóch ramek danych na podstawie 'main_genre'\n",
    "    comparison_df = comparison_df.join(subgenres_df, on=[\"artist_main_genres\", column]).orderBy(column,col(\"genre_popularity\").desc())    \n",
    "    comparison_df = comparison_df.select(column,\"artist_main_genres\",\"artist_subgenres\",\"genre_popularity\",\"number_of_tracks\" )\n",
    "    # Utwórz okno partycjonujące po kolumnie 'grupa' i sortujące po kolumnie 'wartość' malejąco\n",
    "    window_spec = Window().partitionBy(column).orderBy(comparison_df[\"genre_popularity\"].desc())\n",
    "    # Dodaj kolumnę rankingu dla każdej grupy\n",
    "    comparison_df = comparison_df.withColumn(\"rank\", rank().over(window_spec))\n",
    "\n",
    "    # Wybierz top 5 z każdej grupy\n",
    "    comparison_df = comparison_df.filter(\"rank <= 5\").drop(\"rank\")\n",
    "    return comparison_df\n",
    "\n",
    "def get_feature_summary(df):\n",
    "    # Lista cech do analizy\n",
    "    selected_features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "                         'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "                         'duration_min']\n",
    "    distribution_summary = df.select(selected_features).describe()\n",
    "    return distribution_summary\n",
    "\n",
    "def process_period_group(df, column):\n",
    "\n",
    "    # Dołączanie kolumny przed grupowaniem\n",
    "    total_days_df = df.groupBy(column).agg(countDistinct(\"date_added\").alias(\"total_days\"))\n",
    "\n",
    "    # Dołączanie wyniku grupowania do ramki danych z wcześniejszymi danymi\n",
    "    df = df.join(total_days_df, on=column, how=\"left\")\n",
    "    \n",
    "    date = spark.sql(\"SELECT current_date() AS current_timestamp\").first().current_timestamp\n",
    "    period_path = f\"analysis/{column}/{date}/\"\n",
    "\n",
    "    compare_released_within_a_month(df,column).write.parquet(period_path+\"compare_with_new_month.parquet\")\n",
    "    compare_released_within_a_year(df,column).write.parquet(period_path+\"compare_with_new_year.parquet\")\n",
    "    get_top_tracks(df,column).write.parquet(period_path+\"top_tracks.parquet\")\n",
    "    get_top_artists(df,column).write.parquet(period_path+\"top_artists.parquet\")\n",
    "    get_top_genres(df,column).write.parquet(period_path+\"top_genres.parquet\")\n",
    "                  \n",
    "    unique_values = df.select(column).distinct().collect()\n",
    "    summary_df= None\n",
    "    for value_row in unique_values:\n",
    "        value = value_row[column]\n",
    "        df_filtered = df.filter(df[column] == value)\n",
    "        summary = get_feature_summary(df_filtered)\n",
    "        summary = summary.withColumn(column, lit(value))\n",
    "        if summary_df:\n",
    "            summary_df = summary_df.union(summary)\n",
    "        else:\n",
    "            summary_df = summary\n",
    "    summary_df.write.parquet(period_path + \"summary_df.parquet\")\n",
    "\n",
    "# UDF (User Defined Function) dla funkcji assign_main_genre\n",
    "assign_main_genre_udf = udf(assign_main_genre, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = remove_conflicting_columns(static_df, [\"track_name\", \"track_artist\",\"popularity\"])\n",
    "dynamic_df = mark_missing_tracks(dynamic_df,static_df)\n",
    "\n",
    "merged_df = merge_dataframes(dynamic_df, static_df)\n",
    "merged_df = assure_date_type(merged_df, ['date_added','track_album_release_date'])\n",
    "merged_df = assign_unique_track_id(merged_df)\n",
    "merged_df = merged_df.filter(col(\"missing\") == False).drop(\"missing\")\n",
    "merged_df = add_seasonal_event_column(merged_df)\n",
    "merged_df = add_track_age(merged_df)\n",
    "merged_df = add_season_column(merged_df)\n",
    "merged_df = transform_artist_genres(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "periods = ['seasonal_event']\n",
    "# periods = ['month','seasonal_event','season','day_of_week']\n",
    "for i in periods:\n",
    "    process_period_group(merged_df, i)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Czas wykonania: {elapsed_time} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
